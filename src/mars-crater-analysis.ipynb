{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T08:26:22.742662Z",
     "iopub.status.busy": "2025-02-21T08:26:22.742326Z",
     "iopub.status.idle": "2025-02-21T08:26:33.956024Z",
     "shell.execute_reply": "2025-02-21T08:26:33.954713Z",
     "shell.execute_reply.started": "2025-02-21T08:26:22.742633Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/site-packages (from scikit-image) (3.4.2)\n",
      "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.10/site-packages (from scikit-image) (11.1.0)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/site-packages (from scikit-image) (24.2)\n",
      "Collecting lazy-loader>=0.4\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Downloading tifffile-2025.2.18-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/site-packages (from scikit-image) (2.0.2)\n",
      "Collecting imageio!=2.35.0,>=2.33\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.8/315.8 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.10/site-packages (from scikit-image) (1.15.1)\n",
      "Installing collected packages: tifffile, lazy-loader, imageio, scikit-image\n",
      "Successfully installed imageio-2.37.0 lazy-loader-0.4 scikit-image-0.25.2 tifffile-2025.2.18\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (11.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image\n",
    "!pip install Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-21T08:26:37.461095Z",
     "iopub.status.busy": "2025-02-21T08:26:37.460763Z",
     "iopub.status.idle": "2025-02-21T08:26:42.198278Z",
     "shell.execute_reply": "2025-02-21T08:26:42.197009Z",
     "shell.execute_reply.started": "2025-02-21T08:26:37.461062Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 08:26:42,045 - INFO - Checking disk space...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "/dev/loop1       20G   76K   20G   1% /kaggle/working\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 08:26:42,068 - INFO - Listing files:\n",
      "ls: cannot access 'C:/MarsData': No such file or directory\n",
      "2025-02-21 08:26:42,077 - INFO - Analyzing lat=-30, lon=60\n",
      "2025-02-21 08:26:42,078 - ERROR - File not found: C:/MarsData/lat-30_lon060.pgm\n",
      "2025-02-21 08:26:42,078 - ERROR - Skipping lat=-30, lon=60\n",
      "2025-02-21 08:26:42,123 - INFO - Memory cleared\n",
      "2025-02-21 08:26:42,124 - INFO - Analyzing lat=30, lon=0\n",
      "2025-02-21 08:26:42,124 - ERROR - File not found: C:/MarsData/lat30_lon000.pgm\n",
      "2025-02-21 08:26:42,125 - ERROR - Skipping lat=30, lon=0\n",
      "2025-02-21 08:26:42,157 - INFO - Memory cleared\n",
      "2025-02-21 08:26:42,158 - INFO - Analyzing lat=30, lon=300\n",
      "2025-02-21 08:26:42,159 - ERROR - File not found: C:/MarsData/lat30_lon300.pgm\n",
      "2025-02-21 08:26:42,159 - ERROR - Skipping lat=30, lon=300\n",
      "2025-02-21 08:26:42,193 - INFO - Memory cleared\n",
      "2025-02-21 08:26:42,194 - ERROR - No tiles processed successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import feature, measure, draw\n",
    "import os\n",
    "import logging\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "class ThemisAnalyzer:\n",
    "    def __init__(self, local_dir='C:/MarsData'):  # Default to local folder\n",
    "        self.resolution_km = 0.1  # ~100 m/pixel, in km\n",
    "        self.elevation_scale = 7 / 1020  # Calibrated for max 7 km depth over 0-255 range\n",
    "        self.local_dir = local_dir\n",
    "        \n",
    "    def get_tile_path(self, lat, lon):\n",
    "        if lat < 0:\n",
    "            filename = f\"lat{lat}_lon{lon:03d}.pgm\"\n",
    "        else:\n",
    "            filename = f\"lat{lat}_lon{lon:03d}.pgm\"\n",
    "        local_path = os.path.join(self.local_dir, filename)\n",
    "        if os.path.exists(local_path):\n",
    "            logger.info(f\"Found file: {local_path}\")\n",
    "            return local_path\n",
    "        else:\n",
    "            logger.error(f\"File not found: {local_path}\")\n",
    "            return None\n",
    "\n",
    "    def process_tile_section(self, image_array, start_row=0, rows=1000):\n",
    "        try:\n",
    "            section = image_array[start_row:start_row + rows, :]\n",
    "            section_resized = section[::4, ::4]\n",
    "            image_normalized = (section_resized - np.min(section_resized)) / (np.max(section_resized) - np.min(section_resized))\n",
    "            \n",
    "            edges = feature.canny(image_normalized, sigma=1)\n",
    "            contours = measure.find_contours(edges, 0.5)\n",
    "            \n",
    "            craters = []\n",
    "            for contour in contours:\n",
    "                contour[:, 0] = contour[:, 0] * 4 + start_row\n",
    "                contour[:, 1] *= 4\n",
    "                mask = np.zeros_like(edges, dtype=bool)\n",
    "                rr, cc = draw.polygon(contour[:, 0], contour[:, 1], mask.shape)\n",
    "                mask[rr, cc] = True\n",
    "                \n",
    "                props = measure.regionprops(mask.astype(int))\n",
    "                if props:\n",
    "                    area = props[0].area\n",
    "                    perimeter = props[0].perimeter\n",
    "                    diameter_km = np.sqrt(4 * area / np.pi) * self.resolution_km * 4\n",
    "                    \n",
    "                    if diameter_km >= 1.0:\n",
    "                        rim_coords = list(zip(contour[:, 0].astype(int), contour[:, 1].astype(int)))\n",
    "                        inside_coords = list(zip(rr, cc))\n",
    "                        rim_elevations = [section_resized[y, x] for y, x in rim_coords if 0 <= y < section_resized.shape[0] and 0 <= x < section_resized.shape[1]]\n",
    "                        inside_elevations = [section_resized[y, x] for y, x in inside_coords if 0 <= y < section_resized.shape[0] and 0 <= x < section_resized.shape[1]]\n",
    "                        \n",
    "                        if rim_elevations and inside_elevations:\n",
    "                            max_rim = np.max(rim_elevations)\n",
    "                            min_inside = np.min(inside_elevations)\n",
    "                            depth_km = (max_rim - min_inside) * self.elevation_scale * 4  # Depth in km\n",
    "                        else:\n",
    "                            depth_km = 0.0\n",
    "\n",
    "                        craters.append({\n",
    "                            'diameter_km': diameter_km,\n",
    "                            'depth_km': depth_km,\n",
    "                            'circularity': 4 * np.pi * area / (perimeter ** 2),\n",
    "                            'center_x': int(np.mean(contour[:, 1])),\n",
    "                            'center_y': int(np.mean(contour[:, 0])),\n",
    "                            'confidence': min(1.0, 4 * np.pi * area / (perimeter ** 2))\n",
    "                        })\n",
    "            return craters\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing section at row {start_row}: {e}\")\n",
    "            return []\n",
    "\n",
    "    def analyze_tile(self, lat, lon):\n",
    "        image_path = self.get_tile_path(lat, lon)\n",
    "        if not image_path:\n",
    "            logger.error(f\"Skipping lat={lat}, lon={lon}\")\n",
    "            return None, None, None\n",
    "            \n",
    "        logger.info(f\"Loading: {os.path.basename(image_path)}\")\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "            img_resized = img.resize((width // 4, height // 4), Image.Resampling.LANCZOS)\n",
    "            image_array = np.array(img_resized, dtype=np.float32)\n",
    "            total_rows = image_array.shape[0]\n",
    "        \n",
    "        section_size = 1000\n",
    "        all_craters = []\n",
    "        \n",
    "        logger.info(\"Detecting craters...\")\n",
    "        for start_row in tqdm(range(0, total_rows, section_size), desc=\"Processing sections\"):\n",
    "            section_craters = self.process_tile_section(image_array, start_row, min(section_size, total_rows - start_row))\n",
    "            all_craters.extend(section_craters)\n",
    "            gc.collect()\n",
    "        \n",
    "        crater_df = pd.DataFrame(all_craters)\n",
    "        stats = {\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'total_craters': len(crater_df),\n",
    "            'mean_diameter': crater_df['diameter_km'].mean() if not crater_df.empty else 0,\n",
    "            'median_diameter': crater_df['diameter_km'].median() if not crater_df.empty else 0,\n",
    "            'min_diameter': crater_df['diameter_km'].min() if not crater_df.empty else 0,\n",
    "            'max_diameter': crater_df['diameter_km'].max() if not crater_df.empty else 0,\n",
    "            'mean_depth': crater_df['depth_km'].mean() if not crater_df.empty else 0,\n",
    "            'median_depth': crater_df['depth_km'].median() if not crater_df.empty else 0,\n",
    "            'min_depth': crater_df['depth_km'].min() if not crater_df.empty else 0,\n",
    "            'max_depth': crater_df['depth_km'].max() if not crater_df.empty else 0\n",
    "        }\n",
    "        \n",
    "        logger.info(\"Creating visualization...\")\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        image_small = image_array[::2, ::2]\n",
    "        image_normalized = (image_small - np.min(image_small)) / (np.max(image_small) - np.min(image_small))\n",
    "        ax.imshow(image_normalized, cmap='gray')\n",
    "        \n",
    "        scale_factor = image_small.shape[0] / total_rows\n",
    "        for _, crater in crater_df.iterrows():\n",
    "            circle = plt.Circle(\n",
    "                (crater['center_x'] * scale_factor, crater['center_y'] * scale_factor),\n",
    "                crater['diameter_km'] / (2 * self.resolution_km) * scale_factor,\n",
    "                fill=False,\n",
    "                color='red',\n",
    "                alpha=crater['confidence']\n",
    "            )\n",
    "            ax.add_patch(circle)\n",
    "            \n",
    "        ax.set_title(f'Craters (Lat {lat}, Lon {lon})')\n",
    "        return crater_df, stats, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Checking disk space...\")\n",
    "    os.system(\"dir\" if os.name == 'nt' else \"df -h .\")\n",
    "    \n",
    "    analyzer = ThemisAnalyzer(local_dir='C:/MarsData')  # Update to your local folder\n",
    "    \n",
    "    tiles_to_process = [\n",
    "        {'lat': -30, 'lon': 60},\n",
    "        {'lat': 30, 'lon': 0},\n",
    "        {'lat': 30, 'lon': 300}\n",
    "    ]\n",
    "    \n",
    "    logger.info(\"Listing files:\")\n",
    "    os.system(\"dir C:\\\\MarsData\" if os.name == 'nt' else \"ls -l C:/MarsData\")\n",
    "    \n",
    "    # Process tiles and collect stats\n",
    "    all_stats = []\n",
    "    for tile in tiles_to_process:\n",
    "        lat = tile['lat']\n",
    "        lon = tile['lon']\n",
    "        try:\n",
    "            logger.info(f\"Analyzing lat={lat}, lon={lon}\")\n",
    "            craters, stats, figure = analyzer.analyze_tile(lat, lon)\n",
    "            \n",
    "            if craters is not None:\n",
    "                logger.info(\"\\nCrater Statistics:\")\n",
    "                for key, value in stats.items():\n",
    "                    if isinstance(value, float):\n",
    "                        logger.info(f\"{key}: {value:.2f} km\")\n",
    "                    else:\n",
    "                        logger.info(f\"{key}: {value}\")\n",
    "                \n",
    "                output_base = f\"themis_lat{lat}_lon{lon:03d}\"\n",
    "                craters.to_csv(f'{output_base}_craters.csv', index=False)\n",
    "                figure.savefig(f'{output_base}_detection.png', dpi=100)\n",
    "                plt.close(figure)\n",
    "                logger.info(f\"Saved {output_base}_craters.csv and {output_base}_detection.png\")\n",
    "                \n",
    "                all_stats.append(stats)\n",
    "            \n",
    "            del craters, stats, figure\n",
    "            gc.collect()\n",
    "            logger.info(\"Memory cleared\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing tile lat={lat}, lon={lon}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Aggregate mean stats with depth\n",
    "    if all_stats:\n",
    "        stats_df = pd.DataFrame(all_stats)\n",
    "        stats_df.to_csv('themis_stats_summary.csv', index=False)\n",
    "        logger.info(\"Saved summary stats to themis_stats_summary.csv\")\n",
    "\n",
    "        combined_craters = pd.concat([pd.read_csv(f'themis_lat{tile[\"lat\"]}_lon{tile[\"lon\"]:03d}_craters.csv') for tile in tiles_to_process], ignore_index=True)\n",
    "        mean_stats = {\n",
    "            'total_craters': len(combined_craters),\n",
    "            'mean_diameter_km': combined_craters['diameter_km'].mean(),\n",
    "            'median_diameter_km': combined_craters['diameter_km'].median(),\n",
    "            'min_diameter_km': combined_craters['diameter_km'].min(),\n",
    "            'max_diameter_km': combined_craters['diameter_km'].max(),\n",
    "            'mean_depth_km': combined_craters['depth_km'].mean(),\n",
    "            'median_depth_km': combined_craters['depth_km'].median(),\n",
    "            'min_depth_km': combined_craters['depth_km'].min(),\n",
    "            'max_depth_km': combined_craters['depth_km'].max()\n",
    "        }\n",
    "        \n",
    "        logger.info(\"\\nAggregated Mean Statistics Across All Tiles (kilometers):\")\n",
    "        for key, value in mean_stats.items():\n",
    "            if isinstance(value, float):\n",
    "                logger.info(f\"{key}: {value:.2f} km\")\n",
    "            else:\n",
    "                logger.info(f\"{key}: {value}\")\n",
    "        \n",
    "        mean_stats_df = pd.DataFrame([mean_stats])\n",
    "        mean_stats_df.to_csv('mean_stats_summary.csv', index=False)\n",
    "        logger.info(\"Saved aggregated mean stats to mean_stats_summary.csv\")\n",
    "    else:\n",
    "        logger.error(\"No tiles processed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T03:24:49.676133Z",
     "iopub.status.busy": "2025-02-21T03:24:49.675749Z",
     "iopub.status.idle": "2025-02-21T03:24:49.711968Z",
     "shell.execute_reply": "2025-02-21T03:24:49.710851Z",
     "shell.execute_reply.started": "2025-02-21T03:24:49.676106Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 03:24:49,689 - INFO - Loaded /kaggle/working/themis_lat-30_lon060_craters.csv with 1856 craters\n",
      "2025-02-21 03:24:49,694 - INFO - Loaded /kaggle/working/themis_lat30_lon000_craters.csv with 1651 craters\n",
      "2025-02-21 03:24:49,698 - INFO - Loaded /kaggle/working/themis_lat30_lon300_craters.csv with 1696 craters\n",
      "2025-02-21 03:24:49,701 - INFO - \n",
      "Aggregated Mean Statistics Across All Tiles (kilometers):\n",
      "2025-02-21 03:24:49,702 - INFO - total_craters: 5203\n",
      "2025-02-21 03:24:49,702 - INFO - mean_diameter_km: 3.98 km\n",
      "2025-02-21 03:24:49,703 - INFO - median_diameter_km: 3.29 km\n",
      "2025-02-21 03:24:49,703 - INFO - min_diameter_km: 1.01 km\n",
      "2025-02-21 03:24:49,704 - INFO - max_diameter_km: 18.13 km\n",
      "2025-02-21 03:24:49,704 - INFO - mean_depth_km: 44.59 km\n",
      "2025-02-21 03:24:49,705 - INFO - median_depth_km: 42.40 km\n",
      "2025-02-21 03:24:49,705 - INFO - min_depth_km: 0.00 km\n",
      "2025-02-21 03:24:49,706 - INFO - max_depth_km: 102.00 km\n",
      "2025-02-21 03:24:49,708 - INFO - Saved aggregated stats to /kaggle/working/mean_stats_summary.csv\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 6709338,
     "sourceId": 10808493,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 223636922,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
